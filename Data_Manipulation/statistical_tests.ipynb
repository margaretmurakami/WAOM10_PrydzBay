{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d1dea8c",
   "metadata": {},
   "source": [
    "### Load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ef78f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify import block, all necessary imports are included\n",
    "# Our regular libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import xarray as xr\n",
    "%matplotlib inline\n",
    "\n",
    "# for the sampling and statistical comparison\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# for plotting\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# for plotting\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import \"/scratch/project_2000789/muramarg/miniconda3/lib/python3.10/site-packages/gsw\"\n",
    "import sys\n",
    "sys.path.append('/scratch/project_2000789/muramarg/miniconda3/lib/python3.10/site-packages/')\n",
    "import gsw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698144ec",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb7bdc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write these to files? does this save time\n",
    "xgrid = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/xgrid.txt\",sep=\",\")\n",
    "ygrid = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/ygrid.txt\",sep=\",\")\n",
    "depth = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/depth.txt\",sep=\",\")\n",
    "\n",
    "xgrid = xgrid.reshape((35040,6586))\n",
    "ygrid = ygrid.reshape((35040,6586))\n",
    "depth = depth.reshape((35040,6586))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4fc4e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/temp.txt\",sep=\",\")\n",
    "salt = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/salt.txt\",sep=\",\")\n",
    "salt = salt.reshape((35040,6586))\n",
    "temp = temp.reshape((35040,6586))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d186178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/mass_wmt.txt\",sep=\",\")\n",
    "wmt = wmt.reshape((35040,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd8c15d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the waom values to gsw values\n",
    "# convert depth to sea pressure\n",
    "long = 73.5089\n",
    "lat = -66.8245\n",
    "p = gsw.p_from_z(z=depth,lat=-66.8245)\n",
    "\n",
    "\n",
    "# convert the absolute salinity from practical salinity\n",
    "SA = gsw.SA_from_SP(salt,p,long,lat)    # absolute salinity from practical salinity\n",
    "\n",
    "# convert potential T to conservative T\n",
    "CT = gsw.CT_from_pt(SA,temp)   # conservative T from potential T\n",
    "\n",
    "# find the potential density from SA, CT, p\n",
    "rho_pot = gsw.rho(SA,CT,p) - 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb6c8202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dT</th>\n",
       "      <th>dsat</th>\n",
       "      <th>drho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.012908</td>\n",
       "      <td>0.228996</td>\n",
       "      <td>0.412905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.480041</td>\n",
       "      <td>0.213917</td>\n",
       "      <td>1.122429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.459540</td>\n",
       "      <td>0.221115</td>\n",
       "      <td>1.208951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.131968</td>\n",
       "      <td>0.027908</td>\n",
       "      <td>0.044213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.182100</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.262203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6581</th>\n",
       "      <td>-0.810600</td>\n",
       "      <td>-0.071541</td>\n",
       "      <td>1.949936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6582</th>\n",
       "      <td>-1.049942</td>\n",
       "      <td>0.006630</td>\n",
       "      <td>2.399629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6583</th>\n",
       "      <td>-0.033861</td>\n",
       "      <td>-0.040905</td>\n",
       "      <td>1.748677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6584</th>\n",
       "      <td>-0.353143</td>\n",
       "      <td>-0.136509</td>\n",
       "      <td>0.035242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6585</th>\n",
       "      <td>-0.230734</td>\n",
       "      <td>-0.181973</td>\n",
       "      <td>1.392013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6586 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dT      dsat      drho\n",
       "0    -0.012908  0.228996  0.412905\n",
       "1     0.480041  0.213917  1.122429\n",
       "2     0.459540  0.221115  1.208951\n",
       "3    -0.131968  0.027908  0.044213\n",
       "4    -0.182100  0.168007  0.262203\n",
       "...        ...       ...       ...\n",
       "6581 -0.810600 -0.071541  1.949936\n",
       "6582 -1.049942  0.006630  2.399629\n",
       "6583 -0.033861 -0.040905  1.748677\n",
       "6584 -0.353143 -0.136509  0.035242\n",
       "6585 -0.230734 -0.181973  1.392013\n",
       "\n",
       "[6586 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the absolute salinity from practical salinity\n",
    "# dSA = SA[-1]-SA[0]\n",
    "dSA = salt[-1]-salt[0]\n",
    "\n",
    "# convert potential T to conservative T\n",
    "# dCT = CT[-1]-CT[0]\n",
    "dCT = temp[-1]-temp[0]\n",
    "\n",
    "# find the potential density from SA, CT, p\n",
    "drho_pot = rho_pot[-1]-rho_pot[0]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"dT\"] = dCT\n",
    "df[\"dsat\"] = dSA\n",
    "df[\"drho\"] = drho_pot\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a4452b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load with 4 groups\n",
    "group1 = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/GroupFiles/group1_4grps.txt\",sep=\",\")\n",
    "group2 = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/GroupFiles/group2_4grps.txt\",sep=\",\")\n",
    "group3 = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/GroupFiles/group3_4grps.txt\",sep=\",\")\n",
    "group4 = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/GroupFiles/group4_4grps.txt\",sep=\",\")\n",
    "\n",
    "group1 = group1.tolist()\n",
    "group1 = [int(x) for x in group1]\n",
    "group2 = group2.tolist()\n",
    "group2 = [int(x) for x in group2]\n",
    "group3 = group3.tolist()\n",
    "group3 = [int(x) for x in group3]\n",
    "group4 = group4.tolist()\n",
    "group4 = [int(x) for x in group4]\n",
    "\n",
    "groups = np.array([group1,group2,group3,group4],dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d0d29",
   "metadata": {},
   "source": [
    "# Kolmogorov-Smirnov\n",
    "### Loop through and save the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstsamp = salt[:,group4].flatten()\n",
    "firstsamp = np.append(firstsamp,temp[:,group4].flatten())\n",
    "\n",
    "reslst = np.array([])\n",
    "for i in range(len(groups)):\n",
    "    \n",
    "    secondsamp = salt[:,groups[i]].flatten()\n",
    "    secondsamp = np.append(secondsamp,temp[:,groups[i]].flatten())\n",
    "    \n",
    "    res = stats.ks_2samp(firstsamp, secondsamp)\n",
    "    reslst = np.append(reslst,res)\n",
    "    \n",
    "    firstsamp = secondsamp.copy()\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d22c32",
   "metadata": {},
   "source": [
    "# Anderson-Darnling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f4ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of AD\n",
    "from scipy.stats import anderson\n",
    "rng = np.random.default_rng()\n",
    "data = rng.random(size=35)\n",
    "res = anderson(data)\n",
    "# res.statistic\n",
    "# res.critical_values\n",
    "# res.significance_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e35387",
   "metadata": {},
   "source": [
    "# Sammon mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4702bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sammon(x, n, display = 2, inputdist = 'raw', maxhalves = 20, maxiter = 500, tolfun = 1e-9, init = 'default'):\n",
    "\n",
    "    import numpy as np \n",
    "    from scipy.spatial.distance import cdist\n",
    "\n",
    "    \"\"\"Perform Sammon mapping on dataset x\n",
    "\n",
    "    y = sammon(x) applies the Sammon nonlinear mapping procedure on\n",
    "    multivariate data x, where each row represents a pattern and each column\n",
    "    represents a feature.  On completion, y contains the corresponding\n",
    "    co-ordinates of each point on the map.  By default, a two-dimensional\n",
    "    map is created.  Note if x contains any duplicated rows, SAMMON will\n",
    "    fail (ungracefully). \n",
    "\n",
    "    [y,E] = sammon(x) also returns the value of the cost function in E (i.e.\n",
    "    the stress of the mapping).\n",
    "\n",
    "    An N-dimensional output map is generated by y = sammon(x,n) .\n",
    "\n",
    "    A set of optimisation options can be specified using optional\n",
    "    arguments, y = sammon(x,n,[OPTS]):\n",
    "\n",
    "       maxiter        - maximum number of iterations\n",
    "       tolfun         - relative tolerance on objective function\n",
    "       maxhalves      - maximum number of step halvings\n",
    "       input          - {'raw','distance'} if set to 'distance', X is \n",
    "                        interpreted as a matrix of pairwise distances.\n",
    "       display        - 0 to 2. 0 least verbose, 2 max verbose.\n",
    "       init           - {'pca', 'cmdscale', random', 'default'}\n",
    "                        default is 'pca' if input is 'raw', \n",
    "                        'msdcale' if input is 'distance'\n",
    "\n",
    "    The default options are retrieved by calling sammon(x) with no\n",
    "    parameters.\n",
    "\n",
    "    File        : sammon.py\n",
    "    Date        : 18 April 2014\n",
    "    Authors     : Tom J. Pollard (tom.pollard.11@ucl.ac.uk)\n",
    "                : Ported from MATLAB implementation by \n",
    "                  Gavin C. Cawley and Nicola L. C. Talbot\n",
    "\n",
    "    Description : Simple python implementation of Sammon's non-linear\n",
    "                  mapping algorithm [1].\n",
    "\n",
    "    References  : [1] Sammon, John W. Jr., \"A Nonlinear Mapping for Data\n",
    "                  Structure Analysis\", IEEE Transactions on Computers,\n",
    "                  vol. C-18, no. 5, pp 401-409, May 1969.\n",
    "\n",
    "    Copyright   : (c) Dr Gavin C. Cawley, November 2007.\n",
    "\n",
    "    This program is free software; you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation; either version 2 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program; if not, write to the Free Software\n",
    "    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Create distance matrix unless given by parameters\n",
    "    if inputdist == 'distance':\n",
    "        D = x\n",
    "        if init == 'default':\n",
    "            init = 'cmdscale'\n",
    "    else:\n",
    "        D = cdist(x, x)\n",
    "        if init == 'default':\n",
    "            init = 'pca'\n",
    "\n",
    "    if inputdist == 'distance' and init == 'pca':\n",
    "        raise ValueError(\"Cannot use init == 'pca' when inputdist == 'distance'\")\n",
    "\n",
    "    if np.count_nonzero(np.diagonal(D)) > 0:\n",
    "        raise ValueError(\"The diagonal of the dissimilarity matrix must be zero\")\n",
    "\n",
    "    # Remaining initialisation\n",
    "    N = x.shape[0]\n",
    "    scale = 0.5 / D.sum()\n",
    "    D = D + np.eye(N)     \n",
    "\n",
    "    if np.count_nonzero(D<=0) > 0:\n",
    "        raise ValueError(\"Off-diagonal dissimilarities must be strictly positive\")   \n",
    "\n",
    "    Dinv = 1 / D\n",
    "    if init == 'pca':\n",
    "        [UU,DD,_] = np.linalg.svd(x)\n",
    "        y = UU[:,:n]*DD[:n] \n",
    "    elif init == 'cmdscale':\n",
    "        from cmdscale import cmdscale\n",
    "        y,e = cmdscale(D)\n",
    "        y = y[:,:n]\n",
    "    else:\n",
    "        y = np.random.normal(0.0,1.0,[N,n])\n",
    "    one = np.ones([N,n])\n",
    "    d = cdist(y,y) + np.eye(N)\n",
    "    dinv = 1. / d\n",
    "    delta = D-d \n",
    "    E = ((delta**2)*Dinv).sum() \n",
    "\n",
    "    # Get on with it\n",
    "    for i in range(maxiter):\n",
    "\n",
    "        # Compute gradient, Hessian and search direction (note it is actually\n",
    "        # 1/4 of the gradient and Hessian, but the step size is just the ratio\n",
    "        # of the gradient and the diagonal of the Hessian so it doesn't\n",
    "        # matter).\n",
    "        delta = dinv - Dinv\n",
    "        deltaone = np.dot(delta,one)\n",
    "        g = np.dot(delta,y) - (y * deltaone)\n",
    "        dinv3 = dinv ** 3\n",
    "        y2 = y ** 2\n",
    "        H = np.dot(dinv3,y2) - deltaone - np.dot(2,y) * np.dot(dinv3,y) + y2 * np.dot(dinv3,one)\n",
    "        s = -g.flatten(order='F') / np.abs(H.flatten(order='F'))\n",
    "        y_old    = y\n",
    "\n",
    "        # Use step-halving procedure to ensure progress is made\n",
    "        for j in range(maxhalves):\n",
    "            s_reshape = np.reshape(s, (-1,n),order='F')\n",
    "            y = y_old + s_reshape\n",
    "            d = cdist(y, y) + np.eye(N)\n",
    "            dinv = 1 / d\n",
    "            delta = D - d\n",
    "            E_new = ((delta**2)*Dinv).sum()\n",
    "            if E_new < E:\n",
    "                break\n",
    "            else:\n",
    "                s = 0.5*s\n",
    "\n",
    "        # Bomb out if too many halving steps are required\n",
    "        if j == maxhalves-1:\n",
    "            print('Warning: maxhalves exceeded. Sammon mapping may not converge...')\n",
    "\n",
    "        # Evaluate termination criterion\n",
    "        if abs((E - E_new) / E) < tolfun:\n",
    "            if display:\n",
    "                print('TolFun exceeded: Optimisation terminated')\n",
    "            break\n",
    "\n",
    "        # Report progress\n",
    "        E = E_new\n",
    "        if display > 1:\n",
    "            print('epoch = %d : E = %12.10f'% (i+1, E * scale))\n",
    "\n",
    "    if i == maxiter-1:\n",
    "        print('Warning: maxiter exceeded. Sammon mapping may not have converged...')\n",
    "\n",
    "    # Fiddle stress to match the original Sammon paper\n",
    "    E = E * scale\n",
    "    \n",
    "    return [y,E]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b48df474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create flattened arrays\n",
    "sample1 = salt[:,group1].flatten()\n",
    "sample1 = np.append(sample1,temp[:,group1].flatten())\n",
    "\n",
    "sample2 = salt[:,group2].flatten()\n",
    "sample2 = np.append(sample2,temp[:,group2].flatten())\n",
    "\n",
    "sample3 = salt[:,group3].flatten()\n",
    "sample3 = np.append(sample3,temp[:,group3].flatten())\n",
    "\n",
    "sample4 = salt[:,group4].flatten()\n",
    "sample4 = np.append(sample4,temp[:,group4].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4b4d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "myx = np.full((308772480,4),np.nan)\n",
    "myx[:,0] = sample1\n",
    "myx[:len(sample2),1] = sample2\n",
    "myx[:len(sample3),2] = sample3\n",
    "myx[:len(sample4),3] = sample4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51cb7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an array of the group label, this will be our target\n",
    "target = np.full(salt[0].shape,np.nan)\n",
    "gn = 1\n",
    "for group in groups:\n",
    "    for i in group:\n",
    "        target[i] = gn\n",
    "    gn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0ea803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saltT = salt.T\n",
    "tempT = temp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafbf075",
   "metadata": {},
   "outputs": [],
   "source": [
    "allts = np.concatenate((saltT,tempT))\n",
    "allts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27964fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target2 = np.concatenate((target,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target2 = target2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f520bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = target2\n",
    "names = np.array([\"Group 1\",\"Group 2\", \"Group 3\",\"Group 4\"])\n",
    "x = saltT\n",
    "# Run the Sammon projection\n",
    "[y,E] = sammon(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ebe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.scatter(y[target ==1, 0], y[target ==1, 1], s=20, c='r', marker='o',label=names[0])\n",
    "plt.scatter(y[target ==2, 0], y[target ==2, 1], s=20, c='b', marker='D',label=names[1])\n",
    "plt.scatter(y[target ==3, 0], y[target ==3, 1], s=20, c='y', marker='v',label=names[2])\n",
    "plt.scatter(y[target ==4, 0], y[target ==4, 1], s=20, c='g', marker='*',label=names[3])\n",
    "plt.title(\"Sammon mapping of salt\")\n",
    "plt.legend(loc=2)\n",
    "\n",
    "plt.savefig(\"/scratch/project_2000789/muramarg/floats_WAOM/meeting_6_26/sammon_salt.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8375b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3b7dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1 : E = 0.0322054247\n",
      "epoch = 2 : E = 0.0320296141\n",
      "epoch = 3 : E = 0.0319550968\n",
      "epoch = 4 : E = 0.0319519500\n",
      "epoch = 5 : E = 0.0310008804\n",
      "epoch = 6 : E = 0.0308858128\n",
      "epoch = 7 : E = 0.0308831332\n",
      "epoch = 8 : E = 0.0307774668\n",
      "epoch = 9 : E = 0.0306755552\n",
      "Warning: maxhalves exceeded. Sammon mapping may not converge...\n",
      "epoch = 10 : E = 0.0306721355\n",
      "epoch = 11 : E = 0.0299948996\n",
      "epoch = 12 : E = 0.0299718074\n",
      "epoch = 13 : E = 0.0297268316\n",
      "epoch = 14 : E = 0.0297233872\n",
      "epoch = 15 : E = 0.0293229095\n",
      "epoch = 16 : E = 0.0292550494\n",
      "epoch = 17 : E = 0.0292474187\n",
      "epoch = 18 : E = 0.0291280853\n",
      "epoch = 19 : E = 0.0289856383\n",
      "epoch = 20 : E = 0.0289818729\n",
      "epoch = 21 : E = 0.0289714781\n",
      "epoch = 22 : E = 0.0286122100\n",
      "epoch = 23 : E = 0.0285801914\n",
      "epoch = 24 : E = 0.0285572111\n",
      "epoch = 25 : E = 0.0285089402\n"
     ]
    }
   ],
   "source": [
    "# target = target2\n",
    "names = np.array([\"Group 1\",\"Group 2\", \"Group 3\",\"Group 4\"])\n",
    "x2 = tempT\n",
    "# Run the Sammon projection\n",
    "[y2,E2] = sammon(x2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d85577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.scatter(y2[target ==1, 0], y2[target ==1, 1], s=20, c='r', marker='o',label=names[0])\n",
    "plt.scatter(y2[target ==2, 0], y2[target ==2, 1], s=20, c='b', marker='D',label=names[1])\n",
    "plt.scatter(y2[target ==3, 0], y2[target ==3, 1], s=20, c='y', marker='v',label=names[2])\n",
    "plt.scatter(y2[target ==4, 0], y2[target ==4, 1], s=20, c='g', marker='*',label=names[3])\n",
    "plt.legend(loc=2)\n",
    "\n",
    "plt.savefig(\"/scratch/project_2000789/muramarg/floats_WAOM/meeting_6_26/sammon_temp.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0c379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
