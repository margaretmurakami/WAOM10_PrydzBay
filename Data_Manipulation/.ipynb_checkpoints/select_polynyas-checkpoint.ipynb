{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd504cbc",
   "metadata": {},
   "source": [
    "### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77f680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1be5c6",
   "metadata": {},
   "source": [
    "### Test our text files that we wrote later in this same file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71c3b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original polynya locations used in submission 1\n",
    "pol_locs = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/pollocs_dsw.txt\",sep=\",\")\n",
    "pol_locs = pol_locs.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae8be2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select from polynyaidx_3_26.txt that forms DSW - this is from our original analysis, should ideally match\n",
    "pol_locs1 = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/polynyaidx_3_26.txt\",sep=\",\")\n",
    "pol_locs1 = pol_locs1.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e10726b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1918,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d(pol_locs,pol_locs1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09d24529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select wmt from 3_26 files\n",
    "wmt = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/wmt_3_26.txt\",sep=\",\")\n",
    "wmt = wmt.reshape((35040,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37051d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5991,)\n"
     ]
    }
   ],
   "source": [
    "columns_with_zero = np.any(wmt == 3, axis=0)\n",
    "indices_with_zero = np.where(columns_with_zero)[0]\n",
    "\n",
    "print(pol_locs1[indices_with_zero].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccac7767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select from polynyaidx_3_26.txt that forms DSW - this is from our original analysis, should ideally match\n",
    "pol_locs2 = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/polynyaidx_3_27_limited.txt\",sep=\",\")\n",
    "pol_locs2 = pol_locs2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fd1139d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1745,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.intersect1d(pol_locs2,pol_locs1[indices_with_zero]).shape\n",
    "np.intersect1d(pol_locs2,pol_locs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c90b3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set these to a file to show an example for clustering\n",
    "pol_locs1[indices_with_zero].tofile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/polynya_-120_1.3e-5.txt\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a7a6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set these to a file to show an example for clustering\n",
    "np.intersect1d(pol_locs2,pol_locs1[indices_with_zero]).tofile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/polynya_-125_1.4e-5.txt\",sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3d2d3e",
   "metadata": {},
   "source": [
    "### Restrict where we set polynyas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8cdeded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5328,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is based on the files polynya_seasons and pollocs_dsw\n",
    "pol_locs = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/polynya_locs.txt\",sep=\",\")\n",
    "pol_locs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235f7dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9aa1d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/points.txt\",sep=\",\")\n",
    "points = points.reshape(391,2)\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c052a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgrid = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/xgrid_dsw.txt\",sep=\",\")\n",
    "ygrid = np.fromfile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/ygrid_dsw.txt\",sep=\",\")\n",
    "\n",
    "xgrid = xgrid.reshape((35040,-1))\n",
    "ygrid = ygrid.reshape((35040,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efefbc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse the points based on this\n",
    "firstx = xgrid[0]\n",
    "firsty = ygrid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f1cd456",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.stack((firstx,firsty)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9015eaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328, 2)\n"
     ]
    }
   ],
   "source": [
    "unique_set = set(map(tuple, points))\n",
    "\n",
    "# Convert the set back to a NumPy array\n",
    "unique_array = np.array(list(unique_set))\n",
    "\n",
    "# Resize the array if needed\n",
    "# For example, if you want to resize it to shape (n, 2), where n is the number of unique points\n",
    "# You might need to adjust n based on the actual number of unique points\n",
    "n = len(unique_array)\n",
    "unique_array = unique_array[:n]\n",
    "\n",
    "print(unique_array.shape)\n",
    "# unique_array is now the list of release points we use in the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6edd47",
   "metadata": {},
   "source": [
    "### Let's find the time steps where there is a polynya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27883a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sh_points(ds,thres,month,xr,yr):\n",
    "    \"\"\"\n",
    "    inputs: the dataset\n",
    "    thres: the threshold value for flux\n",
    "    month: the index of desired month\n",
    "    xr: range of x values to include\n",
    "    yr: range of y values to include\n",
    "    \n",
    "    outputs: the x and y grid locations for the threshold values\n",
    "    \"\"\"\n",
    "    # sh_arr = (ds.shflux.values)[month]\n",
    "    sh_arr = np.mean(ds.shflux.values,axis=0)\n",
    "    locs = np.where(sh_arr < thres)         # set values above the heat loss threshold to 0\n",
    "\n",
    "    # filter by area on the map\n",
    "    newx = np.array([])\n",
    "    newy = np.array([])\n",
    "    for i,j in zip(locs[1],locs[0]):\n",
    "        if (i>xr[0] and i<xr[1]) and (j>yr[0] and j<yr[1]):\n",
    "            newx = np.append(i,newx)\n",
    "            newy = np.append(j,newy)\n",
    "            \n",
    "    return newx,newy\n",
    "\n",
    "def ss_points(ds,thres,month,xr,yr):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        ds: the dataset\n",
    "        thres: the threshold value for flux\n",
    "        month: the index of desired month\n",
    "        xr: range of x values to include\n",
    "        yr: range of y values to include\n",
    "    \n",
    "    outputs: \n",
    "        newx, newy: the x and y grid locations for the threshold values\n",
    "    \"\"\"\n",
    "    \n",
    "    #ss_arr = (ds.ssflux.values)[month]\n",
    "    ss_arr = np.mean(ds.ssflux.values,axis=0)\n",
    "    locs = np.where(ss_arr > thres)         # set values above the heat loss threshold to 0\n",
    "\n",
    "    # filter by area on the map\n",
    "    newx = np.array([])\n",
    "    newy = np.array([])\n",
    "    for i,j in zip(locs[1],locs[0]):\n",
    "        if (i>xr[0] and i<xr[1]) and (j>yr[0] and j<yr[1]):\n",
    "            newx = np.append(i,newx)\n",
    "            newy = np.append(j,newy)\n",
    "            \n",
    "    return newx,newy\n",
    "\n",
    "def mergepoints(x1,y1,x2,y2,h):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        x1,y1: the x and y coordinates of two arrays\n",
    "        x2,y2: the x and y coordinates of two arrays\n",
    "    outputs:\n",
    "        x,y: the combined arrays of two datapoints\n",
    "    \"\"\"\n",
    "    # create the new set of points\n",
    "    pts1 = np.empty((0,2))\n",
    "    pts2 = np.empty((0,2))\n",
    "    \n",
    "    # read through each array, create points as tuples\n",
    "    for i,j in zip(x1,y1):\n",
    "        l = np.array([i,j])\n",
    "        pts1 = np.append(np.array([l]),pts1,axis=0)\n",
    "    for i,j in zip(x2,y2):\n",
    "        l = np.array([i,j])\n",
    "        pts2 = np.append(np.array([l]),pts2,axis=0)\n",
    "        \n",
    "    # union of the two sets\n",
    "    set1 = set([tuple(x) for x in pts1])\n",
    "    set2 = set([tuple(x) for x in pts2])\n",
    "    pts = np.array([x for x in set1 and set2])\n",
    "#     pts2 = np.array([x for x in set1 and set2])\n",
    "#     for pt in pts2:\n",
    "#         #print(pt)\n",
    "#         pts = np.append(np.array([pt]),pts,axis=0)\n",
    "    \n",
    "    # separate into x and y arrays again\n",
    "    x = np.array([])\n",
    "    y = np.array([])\n",
    "    for pt in pts:\n",
    "        #print(pt[0],pt[1])\n",
    "        thish = h[int(pt[1]),int(pt[0])]\n",
    "        #print(thish)\n",
    "        if thish<1000:\n",
    "            x = np.append(pt[0],x)\n",
    "            y = np.append(pt[1],y)\n",
    "    \n",
    "    return x,y\n",
    "    \n",
    "# xh,yh = sh_points(ds,-120,6,[450,600],[300,450])\n",
    "# xs,ys = ss_points(ds,1.3e-5,6,[450,600],[300,450])\n",
    "# plt.plot(xh,yh,'.',color=\"r\",alpha=0.5,label='shflux points')\n",
    "# plt.plot(xs,ys,'.',color=\"b\",alpha=0.5,label='ssflux points')\n",
    "# plt.title(\"sh and ss of points\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d9f3b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1  = xr.open_dataset(\"/scratch/project_2000789/muramarg/waom_total/output_WAOM_check/ocean_avg_0001.nc\")\n",
    "ds2  = xr.open_dataset(\"/scratch/project_2000789/muramarg/waom_total/output_WAOM_check/ocean_avg_0002.nc\")\n",
    "ds3  = xr.open_dataset(\"/scratch/project_2000789/muramarg/waom_total/output_WAOM_check/ocean_avg_0003.nc\")\n",
    "ds4  = xr.open_dataset(\"/scratch/project_2000789/muramarg/waom_total/output_WAOM_check/ocean_avg_0004.nc\")\n",
    "ds5  = xr.open_dataset(\"/scratch/project_2000789/muramarg/waom_total/output_WAOM_check/ocean_avg_0005.nc\")\n",
    "ds6  = xr.open_dataset(\"/scratch/project_2000789/muramarg/waom_total/output_WAOM_check/ocean_avg_0006.nc\")\n",
    "ds7  = xr.open_dataset(\"/scratch/project_2000789/muramarg/waom_total/output_WAOM_check/ocean_avg_0007.nc\")\n",
    "ds8  = xr.open_dataset(\"/scratch/project_2000789/muramarg/waom_total/output_WAOM_check/ocean_avg_0008.nc\")\n",
    "ds9  = xr.open_dataset(\"/scratch/project_2000789/muramarg/waom_total/output_WAOM_check/ocean_avg_0009.nc\")\n",
    "ds10 = xr.open_dataset(\"/scratch/project_2000789/muramarg/waom_total/output_WAOM_check/ocean_avg_0010.nc\")\n",
    "ds11 = xr.open_dataset(\"/scratch/project_2000789/muramarg/waom_total/output_WAOM_check/ocean_avg_0011.nc\")\n",
    "ds12 = xr.open_dataset(\"/scratch/project_2000789/muramarg/waom_total/output_WAOM_check/ocean_avg_0012.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba4e0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = xr.open_dataset(\"/scratch/project_2000789/muramarg/copied_files/waom10extend_grd.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38fbe2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "polynyas = np.zeros((12,104,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "065bbf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(0,)\n",
      "(7,)\n",
      "(63,)\n",
      "(16,)\n",
      "(78,)\n",
      "(75,)\n",
      "(72,)\n",
      "(41,)\n",
      "(2,)\n",
      "(0,)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for ds in ds1,ds2,ds3,ds4,ds5,ds6,ds7,ds8,ds9,ds10,ds11,ds12:\n",
    "    #xh,yh = sh_points(ds,-120,6,[450,600],[300,450])\n",
    "    #xs,ys = ss_points(ds,1.3e-5,6,[450,600],[300,450])\n",
    "    xh,yh = sh_points(ds,-125,6,[450,600],[300,450])\n",
    "    xs,ys = ss_points(ds,1.4e-5,6,[450,600],[300,450])\n",
    "    \n",
    "    x,y = mergepoints(xh,yh,xs,ys,dg.h.values)\n",
    "    \n",
    "    stack = np.stack((x,y)).T\n",
    "    intersect = np.zeros(unique_array.shape)\n",
    "    print(x.shape)\n",
    "    #stackflat = print(stack.shape)\n",
    "    #print(unique_array.shape)\n",
    "    for p in range(len(stack)):\n",
    "        if stack[p] in unique_array:\n",
    "            intersect[p] = stack[p]\n",
    "            \n",
    "            \n",
    "    non_zero_rows = ~np.all(intersect == 0, axis=1)\n",
    "\n",
    "    # Filter out rows with all zeros\n",
    "    arr_filtered = intersect[non_zero_rows]\n",
    "    polynyas[i,:arr_filtered.shape[0],:]=arr_filtered\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98a76c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can use arr_filtered to create a new list of indices in the array\n",
    "df = xr.open_dataset(\"/scratch/project_2000789/muramarg/waom_total/output_WAOM_check/ocean_flt.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "739ef7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgrid = df.Xgrid.values\n",
    "ygrid = df.Ygrid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6096576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[471. 471. 471. ... 597. 597. 597.]\n"
     ]
    }
   ],
   "source": [
    "first_non_nan_indices = []\n",
    "for col in range(xgrid.shape[1]):\n",
    "    # Find indices of non-NaN values in the column\n",
    "    non_nan_indices = np.where(~np.isnan(xgrid[:, col]))[0]\n",
    "    if len(non_nan_indices) > 0:\n",
    "        # Select the first non-NaN value index\n",
    "        first_non_nan_indices.append(non_nan_indices[0])\n",
    "\n",
    "# Now, first_non_nan_indices contains the index of the first non-NaN value in each column\n",
    "# Use these indices to extract the corresponding values\n",
    "first_non_nan_values = xgrid[first_non_nan_indices, np.arange(xgrid.shape[1])]\n",
    "\n",
    "print(first_non_nan_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ea889d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[369. 369. 369. ... 428. 428. 428.]\n"
     ]
    }
   ],
   "source": [
    "first_non_nan_indices = []\n",
    "for col in range(ygrid.shape[1]):\n",
    "    # Find indices of non-NaN values in the column\n",
    "    non_nan_indices = np.where(~np.isnan(ygrid[:, col]))[0]\n",
    "    if len(non_nan_indices) > 0:\n",
    "        # Select the first non-NaN value index\n",
    "        first_non_nan_indices.append(non_nan_indices[0])\n",
    "\n",
    "# Now, first_non_nan_indices contains the index of the first non-NaN value in each column\n",
    "# Use these indices to extract the corresponding values\n",
    "first_non_nan_valuesy = ygrid[first_non_nan_indices, np.arange(ygrid.shape[1])]\n",
    "\n",
    "print(first_non_nan_valuesy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "734b08d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20332, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_flt = np.stack((first_non_nan_values,first_non_nan_valuesy)).T\n",
    "stack_flt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d7765eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[471., 369.],\n",
       "       [471., 369.],\n",
       "       [471., 369.],\n",
       "       ...,\n",
       "       [597., 428.],\n",
       "       [597., 428.],\n",
       "       [597., 428.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each release point in stack_flt should be released (52 for each)\n",
    "stack_flt  # 391 points, 52 for each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9656c90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    }
   ],
   "source": [
    "point_tuples = [tuple(row) for row in stack_flt]\n",
    "\n",
    "# Use set() to find unique tuples\n",
    "unique_points = set(point_tuples)\n",
    "\n",
    "# Get the number of unique points\n",
    "num_unique_points = len(unique_points)\n",
    "\n",
    "print(num_unique_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4515dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 4 5 4 4 4 5 4 5 4 5 \n",
    "\n",
    "# for i in stack_flt\n",
    "stupid_months = np.array([0,0,0,0,1,1,1,1,2,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,6,6,6,6,6,7,7,7,7,8,8,8,8,9,9,9,9,9,10,10,10,10,11,11,11,11,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c6b71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = np.zeros((20332))\n",
    "pol_idx = np.array([],dtype=int)\n",
    "firsti = 0\n",
    "\n",
    "for point in range(len(stack_flt)):\n",
    "    # get the points from the current polynya\n",
    "    mym = stupid_months[firsti]\n",
    "    mym = polynyas[mym]\n",
    "    \n",
    "    # see if point is in mym\n",
    "    if stack_flt[point] in mym:\n",
    "        pol_idx = np.append(pol_idx,point)\n",
    "    \n",
    "    firsti += 1\n",
    "    if firsti == 51:\n",
    "        firsti = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68df7ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_idx.tofile(\"/scratch/project_2000789/muramarg/floats_WAOM/text_files/polynyaidx_3_27_limited.txt\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc17561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
